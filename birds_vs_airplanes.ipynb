{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2d9fe286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "50ef0845",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_path = '../data-unversioned/p1ch7/'\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ])) \n",
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6342ac8e",
   "metadata": {},
   "source": [
    "# Distinguishing birds from airplanes\n",
    "Jane, our friend at the bird-watching club, has set up a fleet of cameras in the woods south of the airport. The cameras are supposed to save a shot when something enters the frame and upload it to the club’s real-time bird-watching blog. The problem is that a lot of planes coming and going from the airport end up triggering the camera,]\n",
    "\n",
    "\n",
    "Jane spends a lot of time deleting pictures of airplanes from the blog. What she needs is an automated system like that shown in figure 7.6. Instead of manually delet- ing, she needs a neural network—an AI if we’re into fancy marketing speak—to throw away the airplanes right away.\n",
    "No worries! We’ll take care of that, no problem—we just got the perfect dataset for it (what a coincidence, right?). We’ll pick out all the birds and airplanes from our CIFAR-10 dataset and build a neural network that can tell birds and airplanes apart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a9fc01",
   "metadata": {},
   "source": [
    "## CIFAR-10 Dataset\n",
    "It consists of 60,000 tiny 32 × 32 color (RGB) images, labeled with an inte- ger corresponding to 1 of 10 classes: airplane (0), automobile (1), bird (2), cat (3), deer (4), dog (5), frog (6), horse (7), ship (8), and truck (9).1 Nowadays, CIFAR-10 is considered too simple for developing or validating new research. We will use the torchvision module to automatically download the dataset and load it as a collection of PyTorch tensors.\n",
    "## Building the dataset\n",
    "We somewhat arbitrarily pick 512 hidden features. A neural network needs at least one hidden layer (of activations, so two modules) with a nonlinearity in between in order to be able to learn arbitrary functions.\n",
    "## Tanh Hidden Layer Activation Function\n",
    "The hyperbolic tangent activation function is also referred to simply as the Tanh (also “tanh” and “TanH“) function.\n",
    "It is very similar to the sigmoid activation function and even has the same S-shape.The function takes any real value as input and outputs values in the range -1 to 1. The larger the input (more positive), the closer the output value will be to 1.0, whereas the smaller the input (more negative), the closer the output will be to -1.0.\n",
    "\n",
    "This means that using the tanh activation function results in higher values of gradient during training and higher updates in the weights of the network. So, if we want strong gradients and big learning steps, we should use the tanh activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e3ac8a",
   "metadata": {},
   "source": [
    "Check this link to see activation functions: Sigmoid vs Tanh\n",
    "\n",
    "https://www.baeldung.com/cs/sigmoid-vs-tanh-functions#:~:text=This%20means%20that%20using%20the,use%20the%20tanh%20activation%20function.\n",
    "\n",
    "When we are using these activation functions in a neural network, our data are usually centered around zero. So, we should focus our attention on the behavior of each gradient in the region near zero.\n",
    "\n",
    "We observe that the gradient of tanh is four times greater than the gradient of the sigmoid function. This means that using the tanh activation function results in higher values of gradient during training and higher updates in the weights of the network. So, if we want strong gradients and big learning steps, we should use the tanh activation function.\n",
    "\n",
    "Another difference is that the output of tanh is symmetric around zero leading to faster convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "010db877",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "\n",
    "cifar2 = [(img, label_map[label]) for img, label in cifar10 if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label]) for img, label in cifar10_val if label in [0, 2]]\n",
    "\n",
    "\n",
    "n_out = 2\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                3072,  # <1>\n",
    "                512,   # <2>\n",
    "            ),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(\n",
    "                512,   # <2>\n",
    "                n_out, # <3>\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfee146",
   "metadata": {},
   "source": [
    "Softmax is a function that takes a vector of values and produces another vector of the same dimension, where the values satisfy the constraints we just listed to represent probabilities. The expression for softmax is shown in figure 7.8.\n",
    "That is, we take the elements of the vector, compute the elementwise exponential, and divide each element by the sum of exponentials. In code, it’s something like this:\n",
    "\n",
    "for bird (the order is arbitrary). This will still work if we have 10 classes, as in the full CIFAR-10 dataset; we’ll just have a vector of length 10.6\n",
    "In the ideal case, the network would output torch.tensor([1.0, 0.0]) for an air- plane and torch.tensor([0.0, 1.0]) for a bird. Practically speaking, since our clas- sifier will not be perfect, we can expect the network to output something in between. The key realization in this case is that we can interpret our output as probabilities: the first entry is the probability of “airplane,” and the second is the probability of “bird.”\n",
    "Casting the problem in terms of probabilities imposes a few extra constraints on the outputs of our network:\n",
    " Each element of the output must be in the [0.0, 1.0] range (a probability of an outcome cannot be less than 0 or greater than 1).\n",
    " The elements of the output must add up to 1.0 (we’re certain that one of the two outcomes will occur).\n",
    "It sounds like a tough constraint to enforce in a differentiable way on a vector of num- bers. Yet there’s a very smart trick that does exactly that, and it’s differentiable: it’s called softmax.\n",
    "\n",
    "### Representing the output as probabilities\n",
    "Softmax is a function that takes a vector of values and produces another vector of the same dimension, where the values satisfy the constraints we just listed to represent probabilities. The expression for softmax.\n",
    "That is, we take the elements of the vector, compute the elementwise exponential, and divide each element by the sum of exponentials. In code, it’s something like this:\n",
    "\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "def softmax(x): <br>\n",
    "&emsp; return torch.exp(x) / torch.exp(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f579f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2),\n",
    "            nn.LogSoftmax(dim=1))\n",
    "loss_fn = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "24bd67ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2))\n",
    "loss_fn =  nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7434943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer_1 = optim.SGD(model_1.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "160e7c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\n",
      "torch.Size([3, 32, 32])\n",
      "Modified input to feed model\n",
      "torch.Size([1, 3072])\n"
     ]
    }
   ],
   "source": [
    "img, label = cifar2[0]\n",
    "plt.title('A random bird from the CIFAR-10 dataset (after normalization)')\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.show()\n",
    "img_batch = img.view(-1).unsqueeze(0)\n",
    "print('Input')\n",
    "print(img.size())\n",
    "print('Modified input to feed model')\n",
    "print(img_batch.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed81a596",
   "metadata": {},
   "source": [
    "#### negative log likelihood (NLL)\n",
    "We want a loss function that is very high when the likelihood is low: so low that the alternatives have a higher prob- ability. Conversely, the loss should be low when the likelihood is higher than the alter- natives, and we’re not really fixated on driving the probability up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "51da1149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.183565\n",
      "Epoch: 1, Loss: 0.205889\n",
      "Epoch: 2, Loss: 0.529314\n",
      "Epoch: 3, Loss: 0.360140\n",
      "Epoch: 4, Loss: 0.500301\n",
      "Epoch: 5, Loss: 0.207041\n",
      "Epoch: 6, Loss: 0.155241\n",
      "Epoch: 7, Loss: 0.412783\n",
      "Epoch: 8, Loss: 0.652977\n",
      "Epoch: 9, Loss: 0.307352\n",
      "Epoch: 10, Loss: 0.528514\n",
      "Epoch: 11, Loss: 0.485555\n",
      "Epoch: 12, Loss: 0.346943\n",
      "Epoch: 13, Loss: 0.214458\n",
      "Epoch: 14, Loss: 0.192094\n",
      "Epoch: 15, Loss: 0.434326\n",
      "Epoch: 16, Loss: 0.457395\n",
      "Epoch: 17, Loss: 0.215427\n",
      "Epoch: 18, Loss: 0.179709\n",
      "Epoch: 19, Loss: 0.362844\n",
      "Epoch: 20, Loss: 0.314118\n",
      "Epoch: 21, Loss: 0.217104\n",
      "Epoch: 22, Loss: 0.174974\n",
      "Epoch: 23, Loss: 0.170738\n",
      "Epoch: 24, Loss: 0.389453\n",
      "Epoch: 25, Loss: 0.104886\n",
      "Epoch: 26, Loss: 0.193833\n",
      "Epoch: 27, Loss: 0.236603\n",
      "Epoch: 28, Loss: 0.388235\n",
      "Epoch: 29, Loss: 0.199364\n",
      "Epoch: 30, Loss: 0.165282\n",
      "Epoch: 31, Loss: 0.218501\n",
      "Epoch: 32, Loss: 0.061459\n",
      "Epoch: 33, Loss: 0.169988\n",
      "Epoch: 34, Loss: 0.434620\n",
      "Epoch: 35, Loss: 0.015461\n",
      "Epoch: 36, Loss: 0.370309\n",
      "Epoch: 37, Loss: 0.043004\n",
      "Epoch: 38, Loss: 0.217591\n",
      "Epoch: 39, Loss: 0.029776\n",
      "Epoch: 40, Loss: 0.103872\n",
      "Epoch: 41, Loss: 0.104564\n",
      "Epoch: 42, Loss: 0.033313\n",
      "Epoch: 43, Loss: 0.010242\n",
      "Epoch: 44, Loss: 0.034903\n",
      "Epoch: 45, Loss: 0.194687\n",
      "Epoch: 46, Loss: 0.013480\n",
      "Epoch: 47, Loss: 0.036687\n",
      "Epoch: 48, Loss: 0.021486\n",
      "Epoch: 49, Loss: 0.050054\n",
      "Epoch: 50, Loss: 0.010954\n",
      "Epoch: 51, Loss: 0.019297\n",
      "Epoch: 52, Loss: 0.012947\n",
      "Epoch: 53, Loss: 0.002868\n",
      "Epoch: 54, Loss: 0.010221\n",
      "Epoch: 55, Loss: 0.014531\n",
      "Epoch: 56, Loss: 0.006495\n",
      "Epoch: 57, Loss: 0.016996\n",
      "Epoch: 58, Loss: 0.001454\n",
      "Epoch: 59, Loss: 0.011267\n",
      "Epoch: 60, Loss: 0.000683\n",
      "Epoch: 61, Loss: 0.002090\n",
      "Epoch: 62, Loss: 0.022372\n",
      "Epoch: 63, Loss: 0.007003\n",
      "Epoch: 64, Loss: 0.003492\n",
      "Epoch: 65, Loss: 0.002638\n",
      "Epoch: 66, Loss: 0.029289\n",
      "Epoch: 67, Loss: 0.018897\n",
      "Epoch: 68, Loss: 0.023298\n",
      "Epoch: 69, Loss: 0.006580\n",
      "Epoch: 70, Loss: 0.003978\n",
      "Epoch: 71, Loss: 0.000535\n",
      "Epoch: 72, Loss: 0.000380\n",
      "Epoch: 73, Loss: 0.003294\n",
      "Epoch: 74, Loss: 0.024936\n",
      "Epoch: 75, Loss: 0.005051\n",
      "Epoch: 76, Loss: 0.000682\n",
      "Epoch: 77, Loss: 0.001648\n",
      "Epoch: 78, Loss: 0.006571\n",
      "Epoch: 79, Loss: 0.001299\n",
      "Epoch: 80, Loss: 0.001229\n",
      "Epoch: 81, Loss: 0.002873\n",
      "Epoch: 82, Loss: 0.000625\n",
      "Epoch: 83, Loss: 0.002141\n",
      "Epoch: 84, Loss: 0.000424\n",
      "Epoch: 85, Loss: 0.007717\n",
      "Epoch: 86, Loss: 0.001602\n",
      "Epoch: 87, Loss: 0.002384\n",
      "Epoch: 88, Loss: 0.000523\n",
      "Epoch: 89, Loss: 0.001056\n",
      "Epoch: 90, Loss: 0.000085\n",
      "Epoch: 91, Loss: 0.001881\n",
      "Epoch: 92, Loss: 0.000572\n",
      "Epoch: 93, Loss: 0.000437\n",
      "Epoch: 94, Loss: 0.006017\n",
      "Epoch: 95, Loss: 0.000370\n",
      "Epoch: 96, Loss: 0.001678\n",
      "Epoch: 97, Loss: 0.000633\n",
      "Epoch: 98, Loss: 0.000375\n",
      "Epoch: 99, Loss: 0.000939\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5ab100",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "print(\"Accuracy:\", correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b4af5d",
   "metadata": {},
   "source": [
    "This means we are training a classifier that is not translation-invariant, so we’re forced to use a lot of capacity for learning translated replicas if we want to hope to do well on the validation set. This means a network that has been trained to recognize a Spitfire starting at position x1,y1 will not be able to recognize the exact same Spitfire starting at position x2,y2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
