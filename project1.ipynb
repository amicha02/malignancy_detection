{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be571d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417b09b1",
   "metadata": {},
   "source": [
    "In order to run the AlexNet architecture on an input image, we can create an instance of the AlexNet class. This is how it’s done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7f4bba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = models.AlexNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a11d8e",
   "metadata": {},
   "source": [
    "Let’s create an instance of the network now. We’ll pass an argument that will instruct the function to download the weights of resnet101 trained on the ImageNet dataset, with 1.2 million images and 1,000 categories:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e7c1cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/egads1/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/egads1/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet101(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf1c861",
   "metadata": {},
   "source": [
    "Let's take a peek at what a resnet101 looks like. This gives us a textual representation providing details about the structure of the network. For now, this will be information overload, but as we progress through this project, we’ll increase our ability to understand what this code is telling us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a52a5e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794f401e",
   "metadata": {},
   "source": [
    "In this case, we defined a preprocess function that will scale the input image to 256 × 256, crop the image to 224 × 224 around the center, transform it to a tensor (a PyTorch multidimensional array: in this case, a 3D array with color, height, and width), and normalize its RGB (red, green, blue) components so that they have defined means and standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac21ac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )])\n",
    "img = Image.open(\"data/project1/croco.jpeg\")\n",
    "img_t = preprocess(img)\n",
    "batch_t = torch.unsqueeze(img_t, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69152ea",
   "metadata": {},
   "source": [
    "The process of running a trained model on new data is called inference in deep learn- ing circles. In order to do inference, we need to put the network in eval mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6fa9ee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.eval()\n",
    "\n",
    "out = resnet(batch_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f124a4ce",
   "metadata": {},
   "source": [
    "Let’s load the file containing the 1,000 labels for the ImageNet dataset classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f11b0065",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/project1/imagenet_classes.txt') as f:\n",
    "    labels = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298419cd",
   "metadata": {},
   "source": [
    "We determine the index corresponding to the maximum score in the out tensor we obtained previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cb8b525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, index = torch.max(out, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf11d974",
   "metadata": {},
   "source": [
    "We also use torch.nn.functional.softmax (http://mng.bz/BYnq) to nor- malize our outputs to the range [0, 1], and divide by the sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4694b270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "African crocodile, Nile crocodile, Crocodylus niloticus\n",
      "99.9884262084961\n"
     ]
    }
   ],
   "source": [
    "percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
    "\n",
    "print(labels[index[0]])\n",
    "print(percentage[index[0]].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "75b80585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('African crocodile, Nile crocodile, Crocodylus niloticus', 99.9884262084961),\n",
       " ('American alligator, Alligator mississipiensis', 0.010866689495742321),\n",
       " ('alligator lizard', 0.0003804856678470969),\n",
       " ('Komodo dragon, Komodo lizard, dragon lizard, giant lizard, Varanus komodoensis',\n",
       "  0.00010293831292074174),\n",
       " ('frilled lizard, Chlamydosaurus kingi', 2.4088680220302194e-05)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, indices = torch.sort(out, descending=True)\n",
    "[(labels[idx], percentage[idx].item()) for idx in indices[0][:5]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
